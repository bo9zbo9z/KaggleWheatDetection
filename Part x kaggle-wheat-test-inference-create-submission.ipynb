{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011811,
     "end_time": "2020-09-22T20:29:53.820986",
     "exception": false,
     "start_time": "2020-09-22T20:29:53.809175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Forked from  [Object Detection with YOLO blog series](https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html)\n",
    "\n",
    "Notebooks were only modified as needed, vast majority of the contents are from fairyonice.github repository.\n",
    "\n",
    "My changes covering all notebooks were:\n",
    "- Use Kaggle Wheat Detection data\n",
    "- Migrate to TF 2.x\n",
    "- Modified Data Generator and Loss to remove tensor error\n",
    "- New notebook using albumentations for image & box augmentation\n",
    "- New Kaggle submission notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010526,
     "end_time": "2020-09-22T20:29:53.842280",
     "exception": false,
     "start_time": "2020-09-22T20:29:53.831754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "This is the sixth blog post of [Object Detection with YOLO blog series](https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html). This blog performs inference using the model in trained in [Part 5 Object Detection with Yolo using VOC 2012 data - training](https://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html).\n",
    "I will use PASCAL VOC2012 data. \n",
    "This blog assumes that the readers have read the previous blog posts - [Part 1](https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html), [Part 2](https://fairyonice.github.io/Part%202_Object_Detection_with_Yolo_using_VOC_2014_data_input_and_output_encoding.html), [Part 3](https://fairyonice.github.io/Part_3_Object_Detection_with_Yolo_using_VOC_2012_data_model.html), [Part 4](https://fairyonice.github.io/Part_4_Object_Detection_with_Yolo_using_VOC_2012_data_loss.html), [Part 5](https://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html).\n",
    "\n",
    "## Andrew Ng's YOLO lecture\n",
    "- [Neural Networks - Bounding Box Predictions](https://www.youtube.com/watch?v=gKreZOUi-O0&t=0s&index=7&list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs)\n",
    "- [C4W3L06 Intersection Over Union](https://www.youtube.com/watch?v=ANIzQ5G-XPE&t=7s)\n",
    "- [C4W3L07 Nonmax Suppression](https://www.youtube.com/watch?v=VAo84c1hQX8&t=192s)\n",
    "- [C4W3L08 Anchor Boxes](https://www.youtube.com/watch?v=RTlwl2bv0Tg&t=28s)\n",
    "- [C4W3L09 YOLO Algorithm](https://www.youtube.com/watch?v=9s_FpMpdYW8&t=34s)\n",
    "\n",
    "## Reference\n",
    "- [You Only Look Once:Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf) \n",
    "\n",
    "- [YOLO9000:Better, Faster, Stronger](https://arxiv.org/pdf/1612.08242.pdf)\n",
    " \n",
    "- [experiencor/keras-yolo2](https://github.com/experiencor/keras-yolo2)\n",
    "\n",
    "## Reference in blog\n",
    "- [Part 1 Object Detection using YOLOv2 on Pascal VOC2012 - anchor box clustering](https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html)\n",
    "- [Part 2 Object Detection using YOLOv2 on Pascal VOC2012 - input and output encoding](https://fairyonice.github.io/Part%202_Object_Detection_with_Yolo_using_VOC_2014_data_input_and_output_encoding.html)\n",
    "- [Part 3 Object Detection using YOLOv2 on Pascal VOC2012 - model](https://fairyonice.github.io/Part_3_Object_Detection_with_Yolo_using_VOC_2012_data_model.html)\n",
    "- [Part 4 Object Detection using YOLOv2 on Pascal VOC2012 - loss](https://fairyonice.github.io/Part_4_Object_Detection_with_Yolo_using_VOC_2012_data_loss.html)\n",
    "- [Part 5 Object Detection using YOLOv2 on Pascal VOC2012 - training](https://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html)\n",
    "- [Part 6 Object Detection using YOLOv2 on Pascal VOC 2012 data - inference on image](https://fairyonice.github.io/Part_6_Object_Detection_with_Yolo_using_VOC_2012_data_inference_image.html)\n",
    "- [Part 7 Object Detection using YOLOv2 on Pascal VOC 2012 data - inference on video](https://fairyonice.github.io/Part_7_Object_Detection_with_Yolo_using_VOC_2012_data_inference_video.html)\n",
    "\n",
    "## fairyonice GitHub repository \n",
    "This repository contains all the ipython notebooks in this blog series and the funcitons (See backend.py). \n",
    "- [FairyOnIce/ObjectDetectionYolo](https://github.com/FairyOnIce/ObjectDetectionYolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:29:53.872317Z",
     "iopub.status.busy": "2020-09-22T20:29:53.871663Z",
     "iopub.status.idle": "2020-09-22T20:29:58.897628Z",
     "shell.execute_reply": "2020-09-22T20:29:58.898426Z"
    },
    "papermill": {
     "duration": 5.045115,
     "end_time": "2020-09-22T20:29:58.898659",
     "exception": false,
     "start_time": "2020-09-22T20:29:53.853544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) \n",
      "[GCC 7.3.0]\n",
      "Pandas:  1.1.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "print(sys.version)\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas: \", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:29:58.928951Z",
     "iopub.status.busy": "2020-09-22T20:29:58.927680Z",
     "iopub.status.idle": "2020-09-22T20:30:00.208787Z",
     "shell.execute_reply": "2020-09-22T20:30:00.209505Z"
    },
    "papermill": {
     "duration": 1.29792,
     "end_time": "2020-09-22T20:30:00.209724",
     "exception": false,
     "start_time": "2020-09-22T20:29:58.911804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "class ImageReader(object):\n",
    "    def __init__(self, IMAGE_H, IMAGE_W, norm=None):\n",
    "        '''\n",
    "        IMAGE_H : the height of the rescaled image, e.g., 416\n",
    "        IMAGE_W : the width of the rescaled image, e.g., 416\n",
    "        '''\n",
    "        self.IMAGE_H = IMAGE_H\n",
    "        self.IMAGE_W = IMAGE_W\n",
    "        self.norm = norm\n",
    "\n",
    "    def encode_core(self, image, reorder_rgb=True):\n",
    "        # resize the image to standard size\n",
    "        image = cv2.resize(image, (self.IMAGE_H, self.IMAGE_W))\n",
    "        if reorder_rgb:\n",
    "            image = image[:, :, ::-1]\n",
    "        if self.norm is not None:\n",
    "            image = self.norm(image)\n",
    "        return(image)\n",
    "\n",
    "    def fit(self, train_instance):\n",
    "\n",
    "        if not isinstance(train_instance, dict):\n",
    "            train_instance = {'filename': train_instance}\n",
    "\n",
    "        image_name = train_instance['filename']\n",
    "        image = cv2.imread(image_name)\n",
    "        h, w, c = image.shape\n",
    "        if image is None:\n",
    "            print('Cannot find ', image_name)\n",
    "\n",
    "        image = self.encode_core(image, reorder_rgb=True)\n",
    "\n",
    "        if \"object\" in train_instance.keys():\n",
    "\n",
    "            all_objs = copy.deepcopy(train_instance['object'])\n",
    "\n",
    "            # fix object's position and size\n",
    "            for obj in all_objs:\n",
    "                for attr in ['xmin', 'xmax']:\n",
    "                    obj[attr] = int(obj[attr] * float(self.IMAGE_W) / w)\n",
    "                    obj[attr] = max(min(obj[attr], self.IMAGE_W), 0)\n",
    "\n",
    "                for attr in ['ymin', 'ymax']:\n",
    "                    obj[attr] = int(obj[attr] * float(self.IMAGE_H) / h)\n",
    "                    obj[attr] = max(min(obj[attr], self.IMAGE_H), 0)\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "        return image, all_objs\n",
    "\n",
    "\n",
    "class ImageReaderAlbumentations(ImageReader):\n",
    "    def __init__(self, IMAGE_H, IMAGE_W, augment, norm=None):\n",
    "        super().__init__(IMAGE_H, IMAGE_W, norm)\n",
    "\n",
    "        self.augment = augment\n",
    "\n",
    "    def encode_core(self, image, reorder_rgb=True):\n",
    "        # resize the image to standard size\n",
    "        image = cv2.resize(image, (self.IMAGE_H, self.IMAGE_W))\n",
    "        if reorder_rgb:\n",
    "            image = image[:, :, ::-1]\n",
    "        return(image)\n",
    "\n",
    "    def augment_image(self, image, bboxes):\n",
    "        bbox_labels = np.ones(len(bboxes))\n",
    "\n",
    "        aug_result = self.augment(image=image,\n",
    "                                  bboxes=bboxes,\n",
    "                                  labels=bbox_labels)\n",
    "\n",
    "        return np.array(aug_result['image']), aug_result['bboxes']\n",
    "\n",
    "    def fit(self, file_id):\n",
    "\n",
    "        image = cv2.imread(os.path.join(TEST_DATA_PATH, file_id))\n",
    "        h, w, c = image.shape\n",
    "\n",
    "        if image is None:\n",
    "            raise ValueError('ERROR ImageReaderAlbumentations image: ' + image)\n",
    "\n",
    "        image = self.encode_core(image, reorder_rgb=True)\n",
    "\n",
    "        image, _ = self.augment_image(image, [])\n",
    "        if self.norm is not None:\n",
    "            image = self.norm(image)\n",
    "        return image\n",
    "    \n",
    "class BestAnchorBoxFinder(object):\n",
    "    def __init__(self, ANCHORS):\n",
    "        '''\n",
    "        ANCHORS: a np.array of even number length e.g.\n",
    "\n",
    "        _ANCHORS = [4,2, ##  width=4, height=2,  flat large anchor box\n",
    "                    2,4, ##  width=2, height=4,  tall large anchor box\n",
    "                    1,1] ##  width=1, height=1,  small anchor box\n",
    "        '''\n",
    "        self.anchors = [BoundBox(0, 0, ANCHORS[2*i], ANCHORS[2*i+1])\n",
    "                        for i in range(int(len(ANCHORS)//2))]\n",
    "\n",
    "    def _interval_overlap(self, interval_a, interval_b):\n",
    "        x1, x2 = interval_a\n",
    "        x3, x4 = interval_b\n",
    "        if x3 < x1:\n",
    "            if x4 < x1:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2, x4) - x1\n",
    "        else:\n",
    "            if x2 < x3:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2, x4) - x3\n",
    "\n",
    "    def bbox_iou(self, box1, box2):\n",
    "        intersect_w = self._interval_overlap([box1.xmin, box1.xmax],\n",
    "                                             [box2.xmin, box2.xmax])\n",
    "        intersect_h = self._interval_overlap([box1.ymin, box1.ymax],\n",
    "                                             [box2.ymin, box2.ymax])\n",
    "\n",
    "        intersect = intersect_w * intersect_h\n",
    "\n",
    "        w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "        w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "        union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "        return float(intersect) / union\n",
    "\n",
    "    def find(self, center_w, center_h):\n",
    "        # find the anchor that best predicts this box\n",
    "        best_anchor = -1\n",
    "        max_iou = -1\n",
    "        # each Anchor box is specialized to have a certain shape.\n",
    "        # e.g., flat large rectangle, or small square\n",
    "        shifted_box = BoundBox(0, 0, center_w, center_h)\n",
    "        #  For given object, find the best anchor box!\n",
    "        for i in range(len(self.anchors)):  # run through each anchor box\n",
    "            anchor = self.anchors[i]\n",
    "            iou = self.bbox_iou(shifted_box, anchor)\n",
    "            if max_iou < iou:\n",
    "                best_anchor = i\n",
    "                max_iou = iou\n",
    "        return(best_anchor, max_iou)\n",
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, confidence=None, classes=None):\n",
    "        self.xmin, self.ymin = xmin, ymin\n",
    "        self.xmax, self.ymax = xmax, ymax\n",
    "        # the code below are used during inference\n",
    "        # probability\n",
    "        self.confidence = confidence\n",
    "        # class probaiblities [c1, c2, .. cNclass]\n",
    "        self.set_class(classes)\n",
    "\n",
    "    def set_class(self, classes):\n",
    "        self.classes = classes\n",
    "        self.label = np.argmax(self.classes)\n",
    "\n",
    "    def get_label(self):\n",
    "        return(self.label)\n",
    "\n",
    "    def get_score(self):\n",
    "        return(self.classes[self.label])\n",
    "    \n",
    "# ========================================================================== ##\n",
    "# Part 6 Object Detection with Yolo using VOC 2012 data - inference on image\n",
    "# ========================================================================== ##\n",
    "\n",
    "\n",
    "class OutputRescaler(object):\n",
    "    def __init__(self, ANCHORS):\n",
    "        self.ANCHORS = ANCHORS\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def _softmax(self, x, axis=-1, t=-100.):\n",
    "        x = x - np.max(x)\n",
    "\n",
    "        if np.min(x) < t:\n",
    "            x = x/np.min(x)*t\n",
    "\n",
    "        e_x = np.exp(x)\n",
    "        return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "    def get_shifting_matrix(self, netout):\n",
    "\n",
    "        GRID_H, GRID_W, BOX = netout.shape[:3]\n",
    "        no = netout[..., 0]\n",
    "\n",
    "        ANCHORSw = self.ANCHORS[::2]\n",
    "        ANCHORSh = self.ANCHORS[1::2]\n",
    "\n",
    "        mat_GRID_W = np.zeros_like(no)\n",
    "        for igrid_w in range(GRID_W):\n",
    "            mat_GRID_W[:, igrid_w, :] = igrid_w\n",
    "\n",
    "        mat_GRID_H = np.zeros_like(no)\n",
    "        for igrid_h in range(GRID_H):\n",
    "            mat_GRID_H[igrid_h, :, :] = igrid_h\n",
    "\n",
    "        mat_ANCHOR_W = np.zeros_like(no)\n",
    "        for ianchor in range(BOX):\n",
    "            mat_ANCHOR_W[:, :, ianchor] = ANCHORSw[ianchor]\n",
    "\n",
    "        mat_ANCHOR_H = np.zeros_like(no)\n",
    "        for ianchor in range(BOX):\n",
    "            mat_ANCHOR_H[:, :, ianchor] = ANCHORSh[ianchor]\n",
    "        return(mat_GRID_W, mat_GRID_H, mat_ANCHOR_W, mat_ANCHOR_H)\n",
    "\n",
    "    def fit(self, netout):\n",
    "        GRID_H, GRID_W, BOX = netout.shape[:3]\n",
    "\n",
    "        (mat_GRID_W,\n",
    "         mat_GRID_H,\n",
    "         mat_ANCHOR_W,\n",
    "         mat_ANCHOR_H) = self.get_shifting_matrix(netout)\n",
    "\n",
    "        # bounding box parameters\n",
    "        netout[..., 0] = (self._sigmoid(netout[..., 0]) + mat_GRID_W)/GRID_W  # x      unit: range between 0 and 1\n",
    "        netout[..., 1] = (self._sigmoid(netout[..., 1]) + mat_GRID_H)/GRID_H  # y      unit: range between 0 and 1\n",
    "        netout[..., 2] = (np.exp(netout[..., 2]) * mat_ANCHOR_W)/GRID_W      # width  unit: range between 0 and 1\n",
    "        netout[..., 3] = (np.exp(netout[..., 3]) * mat_ANCHOR_H)/GRID_H      # height unit: range between 0 and 1\n",
    "        # rescale the confidence to range 0 and 1\n",
    "        netout[..., 4] = self._sigmoid(netout[..., 4])\n",
    "        expand_conf = np.expand_dims(netout[..., 4], -1)  # (N grid h , N grid w, N anchor , 1)\n",
    "        # rescale the class probability to range between 0 and 1\n",
    "        # Pr(object class = k) = Pr(object exists) * Pr(object class = k |object exists)\n",
    "        #                      = Conf * P^c\n",
    "        netout[..., 5:] = expand_conf * self._softmax(netout[..., 5:])\n",
    "        # ignore the class probability if it is less than obj_threshold\n",
    "\n",
    "        return(netout)\n",
    "\n",
    "\n",
    "def find_high_class_probability_bbox(netout_scale, obj_threshold):\n",
    "    GRID_H, GRID_W, BOX = netout_scale.shape[:3]\n",
    "\n",
    "    boxes = []\n",
    "    for row in range(GRID_H):\n",
    "        for col in range(GRID_W):\n",
    "            for b in range(BOX):\n",
    "                # from 4th element onwards are confidence and class classes\n",
    "                classes = netout_scale[row, col, b, 5:]\n",
    "\n",
    "                if np.sum(classes) > 0:\n",
    "                    # first 4 elements are x, y, w, and h\n",
    "                    x, y, w, h = netout_scale[row, col, b, :4]\n",
    "                    confidence = netout_scale[row, col, b, 4]\n",
    "                    box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence,\n",
    "                                   classes)\n",
    "                    if box.get_score() > obj_threshold:\n",
    "                        boxes.append(box)\n",
    "    return(boxes)\n",
    "\n",
    "import cv2, copy\n",
    "import seaborn as sns\n",
    "\n",
    "def adjust_minmax(c, _max):\n",
    "    if c < 0:\n",
    "        c = 0\n",
    "    if c > _max:\n",
    "        c = _max\n",
    "    return int(c)\n",
    "\n",
    "def draw_boxes(_image, boxes, labels, obj_baseline=0.05, verbose=False):\n",
    "\n",
    "    image = copy.deepcopy(_image)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    score_rescaled = np.array([box.get_score() for box in boxes])\n",
    "    score_rescaled /= obj_baseline\n",
    "    color_rect, color_text = sns.color_palette(\"husl\", 2)\n",
    "    for sr, box in zip(score_rescaled, boxes):\n",
    "        xmin = adjust_minmax(int(box.xmin*image_w), image_w)\n",
    "        ymin = adjust_minmax(int(box.ymin*image_h), image_h)\n",
    "        xmax = adjust_minmax(int(box.xmax*image_w), image_w)\n",
    "        ymax = adjust_minmax(int(box.ymax*image_h), image_h)\n",
    "\n",
    "        text = \"{:10} {:4.3f}\".format(labels[box.label], box.get_score())\n",
    "        if verbose:\n",
    "            print(\"{} xmin={:4.0f},ymin={:4.0f},xmax={:4.0f},ymax={:4.0f}\".format(text, xmin, ymin, xmax, ymax, text))\n",
    "        #cv2.rectangle(image,\n",
    "                      #pt1=(int(xmin), int(ymin)),\n",
    "                      #pt2=(int(xmax), int(ymax)),\n",
    "                      #color=color_rect,\n",
    "                      #thickness=sr)\n",
    "        cv2.rectangle(image,\n",
    "                      (int(xmin), int(ymin)),\n",
    "                      (int(xmax), int(ymax)),\n",
    "                      color_rect,\n",
    "                      int(sr))\n",
    "        \n",
    "        cv2.putText(img=image,\n",
    "                    text=text,\n",
    "                    org=(xmin + 13, ymin + 13),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1e-3 * image_h,\n",
    "                    color=color_text,\n",
    "                    thickness=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def nonmax_suppression(boxes, iou_threshold, obj_threshold):\n",
    "    bestAnchorBoxFinder = BestAnchorBoxFinder([])\n",
    "\n",
    "    CLASS = len(boxes[0].classes)\n",
    "    index_boxes = []\n",
    "    # suppress non-maximal boxes\n",
    "    for c in range(CLASS):\n",
    "        # extract class probabilities of the c^th class from multiple bbox\n",
    "        class_probability_from_bbxs = [box.classes[c] for box in boxes]\n",
    "\n",
    "        # sorted_indices[i] contains the i^th largest class probabilities\n",
    "        sorted_indices = list(reversed(np.argsort(class_probability_from_bbxs)))\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            # if class probability is zero then ignore\n",
    "            if boxes[index_i].classes[c] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                index_boxes.append(index_i)\n",
    "                for j in range(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "\n",
    "                    # check if the selected i^th bounding box has high IOU with any of the remaining bbox\n",
    "                    # if so, the remaining bbox' class probabilities are set to 0.\n",
    "                    bbox_iou = bestAnchorBoxFinder.bbox_iou(boxes[index_i], boxes[index_j])\n",
    "                    if bbox_iou >= iou_threshold:\n",
    "                        classes = boxes[index_j].classes\n",
    "                        classes[c] = 0\n",
    "                        boxes[index_j].set_class(classes)\n",
    "\n",
    "    newboxes = [boxes[i] for i in index_boxes if boxes[i].get_score() > obj_threshold]\n",
    "\n",
    "    return newboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:00.261065Z",
     "iopub.status.busy": "2020-09-22T20:30:00.259949Z",
     "iopub.status.idle": "2020-09-22T20:30:00.265985Z",
     "shell.execute_reply": "2020-09-22T20:30:00.266774Z"
    },
    "papermill": {
     "duration": 0.040047,
     "end_time": "2020-09-22T20:30:00.266989",
     "exception": false,
     "start_time": "2020-09-22T20:30:00.226942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS = ['wheat']\n",
    "\n",
    "ANCHORS = np.array([0.06960639, 0.06130531,\n",
    "                    0.11246752, 0.10739992])\n",
    "\n",
    "BATCH_SIZE        = 1  # 32 200\n",
    "BOX               = int(len(ANCHORS)/2)\n",
    "TRUE_BOX_BUFFER   = 130\n",
    "IMAGE_H, IMAGE_W  = 1024, 1024\n",
    "GRID_H,  GRID_W   = 32, 32\n",
    "\n",
    "ORIG_IMAGE_SIZE = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:00.320188Z",
     "iopub.status.busy": "2020-09-22T20:30:00.318094Z",
     "iopub.status.idle": "2020-09-22T20:30:00.321034Z",
     "shell.execute_reply": "2020-09-22T20:30:00.321524Z"
    },
    "papermill": {
     "duration": 0.034537,
     "end_time": "2020-09-22T20:30:00.321665",
     "exception": false,
     "start_time": "2020-09-22T20:30:00.287128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Home\n",
    "#ROOT_PATH = \"/Users/john/Documents/Python-Working/Kaggle-global-wheat-detection/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "#MODEL_PATH = \"/Users/john/Documents/Python-Working/2-Kaggle-Wheat/ObjectDetectionYolo-JOHN/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "\n",
    "# Kaggle\n",
    "ROOT_PATH = \"../input/global-wheat-detection/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "MODEL_PATH = \"../input/wheatmodel/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "\n",
    "SUBMISSION_PATH=\"submission.csv\"\n",
    "\n",
    "TEST_DATA_PATH = os.path.join(ROOT_PATH, \"test/\")\n",
    "\n",
    "MODEL_NAME = \"model-wheat-yolo-1024-A2-aug2.h5\"\n",
    "MODEL_PATH = os.path.join(MODEL_PATH, MODEL_NAME)\n",
    "\n",
    "METHOD_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:00.355600Z",
     "iopub.status.busy": "2020-09-22T20:30:00.354988Z",
     "iopub.status.idle": "2020-09-22T20:30:00.361518Z",
     "shell.execute_reply": "2020-09-22T20:30:00.360842Z"
    },
    "papermill": {
     "duration": 0.026945,
     "end_time": "2020-09-22T20:30:00.361640",
     "exception": false,
     "start_time": "2020-09-22T20:30:00.334695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_file_names_Util(file_path,\n",
    "                         image_ext,\n",
    "                         full_file_path=True):\n",
    "    file_list = []\n",
    "    file_names = os.listdir(file_path)\n",
    "    for i, fn in enumerate(file_names):\n",
    "        if fn.endswith(image_ext):\n",
    "            if full_file_path:\n",
    "                file_list.append(fn)\n",
    "            else:\n",
    "                head, tail = os.path.split(fn)\n",
    "                file_list.append(tail[:-4])\n",
    "    return file_list\n",
    "\n",
    "test_image_ids = load_file_names_Util(TEST_DATA_PATH, \".jpg\")\n",
    "\n",
    "if METHOD_TEST:\n",
    "    print(test_image_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:00.392169Z",
     "iopub.status.busy": "2020-09-22T20:30:00.391484Z",
     "iopub.status.idle": "2020-09-22T20:30:05.965624Z",
     "shell.execute_reply": "2020-09-22T20:30:05.964819Z"
    },
    "papermill": {
     "duration": 5.591631,
     "end_time": "2020-09-22T20:30:05.965774",
     "exception": false,
     "start_time": "2020-09-22T20:30:00.374143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...  ../input/wheatmodel/model-wheat-yolo-1024-A2-aug2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1045: UserWarning: backend is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def custom_loss(y_true, y_pred, true_boxes):  # We are only using inference, so dummy loss....\n",
    "    return 1.0\n",
    "\n",
    "print(\"loading... \", MODEL_PATH)\n",
    "model = tf.keras.models.load_model(MODEL_PATH, custom_objects={'tf' : tf, 'custom_loss': custom_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:06.001369Z",
     "iopub.status.busy": "2020-09-22T20:30:06.000551Z",
     "iopub.status.idle": "2020-09-22T20:30:06.961089Z",
     "shell.execute_reply": "2020-09-22T20:30:06.960392Z"
    },
    "papermill": {
     "duration": 0.980136,
     "end_time": "2020-09-22T20:30:06.961218",
     "exception": false,
     "start_time": "2020-09-22T20:30:05.981082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "val_augmentations = albu.Compose([\n",
    "                                   albu.CLAHE(p=1),\n",
    "                                   albu.ToGray(p=1),\n",
    "                                  ], \n",
    "                                  bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    return image / 255.\n",
    "\n",
    "imageReader = ImageReaderAlbumentations(IMAGE_H, IMAGE_W, val_augmentations, norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:06.996836Z",
     "iopub.status.busy": "2020-09-22T20:30:06.995959Z",
     "iopub.status.idle": "2020-09-22T20:30:06.999466Z",
     "shell.execute_reply": "2020-09-22T20:30:06.999917Z"
    },
    "papermill": {
     "duration": 0.024935,
     "end_time": "2020-09-22T20:30:07.000045",
     "exception": false,
     "start_time": "2020-09-22T20:30:06.975110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes):\n",
    "    pred_strings = []\n",
    "    \n",
    "    for box in boxes:\n",
    "        xmin = adjust_minmax(int(box.xmin*IMAGE_W), IMAGE_W)\n",
    "        ymin = adjust_minmax(int(box.ymin*IMAGE_H), IMAGE_H)\n",
    "        xmax = adjust_minmax(int(box.xmax*IMAGE_W), IMAGE_W)\n",
    "        ymax = adjust_minmax(int(box.ymax*IMAGE_H), IMAGE_H)\n",
    "        #print(xmin, ymin, xmax, ymax, box.confidence)\n",
    "        \n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(box.confidence, xmin, ymin, xmax, ymax))\n",
    "\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:07.040433Z",
     "iopub.status.busy": "2020-09-22T20:30:07.039569Z",
     "iopub.status.idle": "2020-09-22T20:30:14.426398Z",
     "shell.execute_reply": "2020-09-22T20:30:14.425800Z"
    },
    "papermill": {
     "duration": 7.412863,
     "end_time": "2020-09-22T20:30:14.426534",
     "exception": false,
     "start_time": "2020-09-22T20:30:07.013671",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if METHOD_TEST:\n",
    "    actual_test_image_ids = ['2fd875eaa.jpg', '53f253011.jpg', 'f5a1f0358.jpg', 'cc3532ff6.jpg']\n",
    "    #actual_test_image_ids = ['1john2.jpg', '2fd875eaa.jpg', '796707dd7.jpg','aac893a91.jpg']\n",
    "    #actual_test_image_ids = [\"1john2.jpg\", \"1jphoto.jpg\"]\n",
    "else:\n",
    "    actual_test_image_ids = test_image_ids\n",
    "    \n",
    "\n",
    "dummy_y = np.zeros((1,GRID_H, GRID_W, BOX, 4+1+len(LABELS)), dtype=np.float32)\n",
    "dummy_box = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4), dtype=np.float32)\n",
    "\n",
    "figsize = (15,15)\n",
    "test_results = []\n",
    "gc_count = 0\n",
    "outputRescaler = OutputRescaler(ANCHORS=ANCHORS)\n",
    "\n",
    "for i in range(len(actual_test_image_ids)):\n",
    "    gc_count = gc_count + 1\n",
    "    if (gc_count % 200) == 0:\n",
    "        gc.collect()\n",
    "\n",
    "    final_boxes = []\n",
    "    image_id = actual_test_image_ids[i]\n",
    "    image = imageReader.fit(image_id)\n",
    "    image = image[np.newaxis, ...]\n",
    "    #print(image.shape)\n",
    "    \n",
    "    y_pred = model.predict([image, dummy_y, dummy_box])[0]\n",
    "    #print(y_pred.shape)\n",
    "    \n",
    "    y_pred_scale = outputRescaler.fit(y_pred)\n",
    "\n",
    "    obj_threshold = 0.4 #0.4\n",
    "    iou_threshold = 0.2 #0.2\n",
    "    boxes = find_high_class_probability_bbox(y_pred_scale, obj_threshold)\n",
    "    if len(boxes) <= 15:\n",
    "        obj_threshold = 0.6 #0.25\n",
    "        iou_threshold = 0.2 #0.01\n",
    "        boxes = find_high_class_probability_bbox(y_pred_scale, obj_threshold)\n",
    "\n",
    "    if len(boxes) > 0:\n",
    "        final_boxes = nonmax_suppression(boxes,\n",
    "                                         iou_threshold=iou_threshold,\n",
    "                                         obj_threshold=obj_threshold)\n",
    "            \n",
    "        result = [image_id, format_prediction_string(final_boxes)]\n",
    "        #\n",
    "    else:\n",
    "        result = [image_id, \"0.0 0 0 0 0\"]\n",
    "    \n",
    "    \n",
    "    test_results.append(result)\n",
    "\n",
    "    if METHOD_TEST:\n",
    "        ima = draw_boxes(image[0], final_boxes, LABELS,verbose=True)\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(\"(\"+str(len(final_boxes))+\")\")\n",
    "        plt.imshow(ima); \n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:14.472997Z",
     "iopub.status.busy": "2020-09-22T20:30:14.468521Z",
     "iopub.status.idle": "2020-09-22T20:30:14.489268Z",
     "shell.execute_reply": "2020-09-22T20:30:14.489731Z"
    },
    "papermill": {
     "duration": 0.047916,
     "end_time": "2020-09-22T20:30:14.489864",
     "exception": false,
     "start_time": "2020-09-22T20:30:14.441948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348a992bb.jpg</td>\n",
       "      <td>0.8976 599 448 719 537 0.8814 737 221 873 308 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796707dd7.jpg</td>\n",
       "      <td>0.8630 893 328 1001 418 0.8537 508 792 594 887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aac893a91.jpg</td>\n",
       "      <td>0.8782 691 382 818 562 0.8743 558 534 684 716 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f5a1f0358.jpg</td>\n",
       "      <td>0.9123 944 427 1024 620 0.8909 690 200 803 292...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cb8d261a3.jpg</td>\n",
       "      <td>0.8539 439 462 559 571 0.8499 167 899 253 988 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id                                   PredictionString\n",
       "0  348a992bb.jpg  0.8976 599 448 719 537 0.8814 737 221 873 308 ...\n",
       "1  796707dd7.jpg  0.8630 893 328 1001 418 0.8537 508 792 594 887...\n",
       "2  aac893a91.jpg  0.8782 691 382 818 562 0.8743 558 534 684 716 ...\n",
       "3  f5a1f0358.jpg  0.9123 944 427 1024 620 0.8909 690 200 803 292...\n",
       "4  cb8d261a3.jpg  0.8539 439 462 559 571 0.8499 167 899 253 988 ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df = pd.DataFrame(test_results, columns =['image_id','PredictionString'])\n",
    "test_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:14.522698Z",
     "iopub.status.busy": "2020-09-22T20:30:14.522140Z",
     "iopub.status.idle": "2020-09-22T20:30:14.737897Z",
     "shell.execute_reply": "2020-09-22T20:30:14.736999Z"
    },
    "papermill": {
     "duration": 0.23441,
     "end_time": "2020-09-22T20:30:14.738005",
     "exception": false,
     "start_time": "2020-09-22T20:30:14.503595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_results_df.to_csv(SUBMISSION_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T20:30:14.772618Z",
     "iopub.status.busy": "2020-09-22T20:30:14.770976Z",
     "iopub.status.idle": "2020-09-22T20:30:14.773568Z",
     "shell.execute_reply": "2020-09-22T20:30:14.774101Z"
    },
    "papermill": {
     "duration": 0.021443,
     "end_time": "2020-09-22T20:30:14.774211",
     "exception": false,
     "start_time": "2020-09-22T20:30:14.752768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if METHOD_TEST:\n",
    "    print(test_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013967,
     "end_time": "2020-09-22T20:30:14.802468",
     "exception": false,
     "start_time": "2020-09-22T20:30:14.788501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 26.782393,
   "end_time": "2020-09-22T20:30:16.516384",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-22T20:29:49.733991",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
